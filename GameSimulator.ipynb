{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Game Bot\n",
    "Let's start with imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import pyscreenshot as ImageGrab\n",
    "from mss import mss\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import concurrent.futures\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import pdb\n",
    "import keras\n",
    "from pathlib import Path\n",
    "import win32api, win32con\n",
    "from random import sample\n",
    "from keras import backend as K\n",
    "import random\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from keras.optimizers import sgd, Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Set up Network\n",
    "* Image input should be 300px by 300px\n",
    "* Output layer should be equal to the number of possible actions, which in this case is 2 (click or no click)\n",
    "* Epsilon-related values concern the ratio between exploring/exploiting. The earlier in the training process we are, the more exploration we will do. In short, we will perform a lot of random actions in the beginning, and gradually allow the model to predict more frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    session.close()\n",
    "    \n",
    "output_size = 2 # either tap or no tap\n",
    "\n",
    "# Deep-Q learning Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.memory = []\n",
    "        self.gamma = 0.9  # decay rate\n",
    "        self.epsilon = 1  # exploration\n",
    "#         self.epsilon_decay = .995\n",
    "        self.epsilon_decay = .2\n",
    "        self.epsilon_min = 0.1\n",
    "        self.learning_rate = 0.0001\n",
    "        self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (8, 8), strides=(4,4),input_shape=(1,300,300), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(64, (4, 4), strides=(2,2), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), strides=(1,1), padding='same', activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='linear'))\n",
    "        model.add(Dense(output_size)) # output layer, todo softmax\n",
    "\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=1e-6))\n",
    "        self.model = model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return int(random.uniform(0, output_size - 1))\n",
    "        act_values = self.model.predict(state)\n",
    "        return int(np.argmax(act_values[0]))\n",
    "\n",
    "    def replay_batch(self, batch):\n",
    "        state, action, reward, next_state, done = self.memory[batch]\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = reward + self.gamma * np.argmax(self.model.predict(next_state))\n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        \n",
    "    def replay(self, batch_size):\n",
    "        print('Replay')\n",
    "        batches = min(batch_size, len(self.memory))\n",
    "        batches = np.random.choice(len(self.memory), batches)\n",
    "        for batch in tqdm(batches):\n",
    "            self.replay_batch(batch)\n",
    "            \n",
    "        self.model.save_weights('modelSmove.h5')\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        print(self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = str(Path.cwd()/'tesseract/tesseract')\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "# orig_stdout = sys.stdout\n",
    "# f = open('out.txt', 'w')\n",
    "# sys.stdout = f\n",
    "\n",
    "x_pad, y_pad = win32api.GetSystemMetrics(0), win32api.GetSystemMetrics(1)\n",
    "game_play_dim = (x_pad*0.715, y_pad*0.04, x_pad, y_pad*0.94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_right = (-int(x_pad*0.04), -int(y_pad*0.9))\n",
    "\n",
    "restart_button = (-int(x_pad*0.23), -int(y_pad*0.5))\n",
    "\n",
    "def mouse_pos(cord):\n",
    "    \"\"\"\n",
    "    Setting mouse position relative to screen dimensions\n",
    "    \"\"\"\n",
    "    win32api.SetCursorPos((x_pad + cord[0], y_pad + cord[1]))\n",
    "\n",
    "def left_hold(movement = None):\n",
    "    \"\"\"\n",
    "    Certain movements need to have the left mouse button held down\n",
    "    In case there is no movement, it is just a regular click\n",
    "    \"\"\"\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0 ,0)\n",
    "    time.sleep(.1)\n",
    "    if movement:\n",
    "        movement()\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0 ,0)\n",
    "\n",
    "def pause():\n",
    "    pass\n",
    "#     mouse_pos(top_right)\n",
    "#     left_hold()\n",
    "    \n",
    "def unpause():\n",
    "    pass\n",
    "#     mouse_pos('x')\n",
    "#     left_hold()\n",
    "\n",
    "def restart():\n",
    "    mouse_pos(restart_button)\n",
    "    left_hold()\n",
    "    time.sleep(0.1)\n",
    "    left_hold()\n",
    "    \n",
    "def reset():\n",
    "    \"\"\" Repeats NO-OP action until a new episode begins. \"\"\"\n",
    "    restart()\n",
    "    time.sleep(.5)\n",
    "    state = take_screenshot()\n",
    "    pause()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(action):\n",
    "    \"\"\" executes action, last action is \"do nothing\" \"\"\"\n",
    "    try:\n",
    "        [left_hold, lambda: None][action]()\n",
    "    except Exception as e:\n",
    "        print(e, action)\n",
    "        \n",
    "def timeit(method):\n",
    "    \"\"\"\n",
    "    Performance Monitoring\n",
    "    \"\"\"\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print(f'{method.__name__}  {(te - ts) * 1000} ms')\n",
    "        return result\n",
    "    return timed\n",
    "\n",
    "def get_cords():\n",
    "    \"\"\"\n",
    "    Useful for debugging\n",
    "    \"\"\"\n",
    "    x,y = win32api.GetCursorPos()\n",
    "#     print (x,y)\n",
    "    x = x - x_pad\n",
    "    y = y - y_pad\n",
    "    print (f'x = {x},y = {y}')\n",
    "\n",
    "test_ob = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "def preprocess(im):\n",
    "    \"\"\"\n",
    "    Before neural net\n",
    "    \"\"\"\n",
    "#     im = im.resize((300,300)).convert('L')\n",
    "#     print(\"[INFO] loading and preprocessing image...\")\n",
    "#     image = img_to_array(im)\n",
    "#     image.reshape((1,) + image.shape)  # this is a Numpy array with shape (1, 3, 300, 300)\n",
    "    im = im.resize((300,300))\n",
    "    im = im.convert('L')\n",
    "    image = img_to_array(im)\n",
    "    image = image.reshape((1,) + image.shape)  # this is a Numpy array with shape (1, 3, 300, 300)\n",
    "\n",
    "    X = []\n",
    "    for batch in test_ob.flow(image, batch_size=1):\n",
    "        X = batch\n",
    "        break\n",
    "    return X\n",
    "\n",
    "def take_screenshot():\n",
    "    with mss() as sct:\n",
    "        monitor = sct.monitors[1]\n",
    "        sct_img = sct.grab(monitor)\n",
    "        return Image.frombytes(\n",
    "            'RGB', sct_img.size, sct_img.bgra,\n",
    "            'raw',\n",
    "            'BGRX',\n",
    "        ).crop(game_play_dim).rotate(90, expand=1) # whole image will not fit without `expand=1`\n",
    "\n",
    "def get_crop_values(left, top, width, height):\n",
    "    return (left, top, left+width, top+height)\n",
    "\n",
    "INTRO_VIEW = 'Skiing'\n",
    "def check_landing(box = get_crop_values(270, 60, 120, 30)):\n",
    "    im = take_screenshot().crop(box)\n",
    "    text = pytesseract.image_to_string(im, config=f'-oem 0 -psm 6 -c tessedit_char_whitelist={INTRO_VIEW}')\n",
    "    return any(val in text for val in INTRO_VIEW)\n",
    "\n",
    "# Check if we did not lose game\n",
    "GAME_OVER = 'Your Score'    \n",
    "def check_game_over(box = get_crop_values(0.36*y_pad, 80, 126, 30)):\n",
    "    im = take_screenshot().crop(box)\n",
    "    text = pytesseract.image_to_string(im)\n",
    "    if any(val in text for val in GAME_OVER):\n",
    "        print('Game over encountered')\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_score(box = get_crop_values(0.422*x_pad, 32, 70, 32)):\n",
    "    im = take_screenshot().crop(box)\n",
    "    im = im.resize((170, 80)).filter(ImageFilter.SMOOTH)\n",
    "    text = pytesseract.image_to_string(im, config=f'--oem 0 -psm 6 -c tessedit_char_whitelist=0123456789')\n",
    "    try:\n",
    "        return int(text)\n",
    "    except Exception as e:\n",
    "        print(e, text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gameplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(action, score):\n",
    "    executor = concurrent.futures.ThreadPoolExecutor()\n",
    "    futures = [executor.submit(get_score), executor.submit(check_game_over)]\n",
    "    res0, res1 = [future.result() for future in concurrent.futures.as_completed(futures, timeout=50.0)]\n",
    "    \n",
    "    if type(res0) == bool:\n",
    "        done = res0\n",
    "        s = res1\n",
    "    else:\n",
    "        s = res0\n",
    "        done = res1\n",
    "\n",
    "    if done or s is None:\n",
    "        reward = 0\n",
    "        s = score\n",
    "    else:\n",
    "        if s is None:\n",
    "            s = score\n",
    "        elif s > score:\n",
    "            reward = 1000\n",
    "        else:\n",
    "            reward =- 250\n",
    "        pause()\n",
    "        select_action(action)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        s = get_score()\n",
    "        if s == -1:\n",
    "            s = score\n",
    "        if done or s is None:\n",
    "            reward = 0\n",
    "            s = score\n",
    "        else:\n",
    "            if s > score:\n",
    "                reward = 1000\n",
    "            else:\n",
    "                reward =- 250\n",
    "    state = take_screenshot()\n",
    "#     time.sleep(0.2)\n",
    "    pause()\n",
    "    return state, reward, done, s, {}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#     check if app booted\n",
    "    if check_landing():\n",
    "        mouse_pos((-210, -400))\n",
    "        left_hold() # focus on window first\n",
    "        time.sleep(0.1)\n",
    "        left_hold()\n",
    "    elif check_game_over():\n",
    "        restart()\n",
    "        \n",
    "    agent = DQNAgent()\n",
    "    try:\n",
    "        agent.model.load_weights('modelSmove.h5')\n",
    "    except:\n",
    "        pass\n",
    "    episodes = 1200\n",
    "\n",
    "    for e in range(episodes):\n",
    "        state = reset()\n",
    "        state = preprocess(state)\n",
    "        score = 0\n",
    "        for time_t in range(5000):\n",
    "            action =  agent.act(state)\n",
    "            next_state, reward, done, score, _ = step(action, score)\n",
    "            next_state = preprocess(next_state)\n",
    "\n",
    "            reward = -5000 if done else reward\n",
    "\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "\n",
    "            state = copy.deepcopy(next_state)\n",
    "\n",
    "            if done:\n",
    "                print(f'episode: {e}/{episodes}, score: {score}')\n",
    "                break\n",
    "        agent.replay(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game over encountered\n",
      "invalid literal for int() with base 10: '' \n",
      "Game over encountered\n",
      "episode: 0/1200, score: 6\n",
      "Replay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▌                                                         | 4/13 [00:30<01:09,  7.73s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-0a3f9e033f2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'episode: {e}/{episodes}, score: {score}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-4dc8c5b9dba5>\u001b[0m in \u001b[0;36mreplay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'modelSmove.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-4dc8c5b9dba5>\u001b[0m in \u001b[0;36mreplay_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mtarget_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mtarget_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2719\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2721\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2693\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RealAnaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TODO: ONLY PERFORM ACTION WHENEVER POSSIBLE, IS WHEN PENGUIN IS TOUCHING ICE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
